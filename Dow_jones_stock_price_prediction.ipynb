{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dow jones stock price prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1P7MgutqDKD3FXBd0f8B17jiobHp2OP4i",
      "authorship_tag": "ABX9TyMR4UErbdtCtl1xXPs6/QAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivu2507/Stock-Price-Prediction-based-on-news/blob/main/Dow_jones_stock_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6JAljjuRNls"
      },
      "source": [
        "# Dow Jones Opening Stock Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vP5ajbBK0zT"
      },
      "source": [
        "The model predicts the opening stock price of dow jones index using the headlines of the previous day published on the previous day by reating wrod embeddings using glove model and using 1 Dimensional convolution for text and LSTM for sequence processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ3wc5lWSI2h"
      },
      "source": [
        "# Importing necessary libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmJkbT8_RMA3",
        "outputId": "78f8ea24-a53a-4c1e-e93b-1cb6349c4942"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-08 12:16:25--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-12-08 12:16:25--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-12-08 12:16:26--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  1.96MB/s    in 16m 56s \n",
            "\n",
            "2020-12-08 12:33:21 (2.04 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nynR3nvSXmS",
        "outputId": "2223aa75-d889-4d9e-d339-396822d1fe16"
      },
      "source": [
        "!unzip glove.840B.300d.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0h8U5OtTVTY",
        "outputId": "6606f577-e2fe-43ae-cf22-28b1003944dd"
      },
      "source": [
        "import nltk \n",
        "nltk.download('stopwords') #To ignore the stopwords such as a, an,the, he, she .etc,. "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tVDughTSgZo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import median_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAfgGMJVTf80"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras import initializers\n",
        "from keras.layers import Dense, Activation, Embedding, Convolution1D, MaxPooling1D, Input, BatchNormalization, Flatten, Reshape, Concatenate, Dropout\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras import regularizers\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxJPysyMsRhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa43e0aa-de50-4d40-fce9-afca7c367284"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HFUF0RCtrbL"
      },
      "source": [
        "dowjones = pd.read_csv('/content/drive/MyDrive/dowjones-news-data/dowjones-news-data/DowJones.csv')\n",
        "news = pd.read_csv('/content/drive/MyDrive/dowjones-news-data/dowjones-news-data/News.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj12mX_wdb-n"
      },
      "source": [
        "# Glimpse and Overview of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSgjHWW3uGxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29036e63-e773-46bd-9ee7-4da0fc2f2655"
      },
      "source": [
        "dowjones.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date         0\n",
              "Open         0\n",
              "High         0\n",
              "Low          0\n",
              "Close        0\n",
              "Volume       0\n",
              "Adj Close    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxzm8ZOaD38G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97de5c60-ce20-46d7-ca51-568880a887f6"
      },
      "source": [
        "news.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date    0\n",
              "News    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ntfzo2WD6Hu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7b201680-ac5b-4cf1-df3e-5a4f34856f5c"
      },
      "source": [
        "dowjones.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>17924.240234</td>\n",
              "      <td>18002.380859</td>\n",
              "      <td>17916.910156</td>\n",
              "      <td>17949.369141</td>\n",
              "      <td>82160000</td>\n",
              "      <td>17949.369141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>17712.759766</td>\n",
              "      <td>17930.609375</td>\n",
              "      <td>17711.800781</td>\n",
              "      <td>17929.990234</td>\n",
              "      <td>133030000</td>\n",
              "      <td>17929.990234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-06-29</td>\n",
              "      <td>17456.019531</td>\n",
              "      <td>17704.509766</td>\n",
              "      <td>17456.019531</td>\n",
              "      <td>17694.679688</td>\n",
              "      <td>106380000</td>\n",
              "      <td>17694.679688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>17190.509766</td>\n",
              "      <td>17409.720703</td>\n",
              "      <td>17190.509766</td>\n",
              "      <td>17409.720703</td>\n",
              "      <td>112190000</td>\n",
              "      <td>17409.720703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-06-27</td>\n",
              "      <td>17355.210938</td>\n",
              "      <td>17355.210938</td>\n",
              "      <td>17063.080078</td>\n",
              "      <td>17140.240234</td>\n",
              "      <td>138740000</td>\n",
              "      <td>17140.240234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date          Open  ...     Volume     Adj Close\n",
              "0  2016-07-01  17924.240234  ...   82160000  17949.369141\n",
              "1  2016-06-30  17712.759766  ...  133030000  17929.990234\n",
              "2  2016-06-29  17456.019531  ...  106380000  17694.679688\n",
              "3  2016-06-28  17190.509766  ...  112190000  17409.720703\n",
              "4  2016-06-27  17355.210938  ...  138740000  17140.240234\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXeBbk9BD8Uh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b79d7440-c933-45d2-86d5-d69304eaeb23"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>IMF chief backs Athens as permanent Olympic host</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>The president of France says if Brexit won, so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>British Man Who Must Give Police 24 Hours' Not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>100+ Nobel laureates urge Greenpeace to stop o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date                                               News\n",
              "0  2016-07-01  A 117-year-old woman in Mexico City finally re...\n",
              "1  2016-07-01   IMF chief backs Athens as permanent Olympic host\n",
              "2  2016-07-01  The president of France says if Brexit won, so...\n",
              "3  2016-07-01  British Man Who Must Give Police 24 Hours' Not...\n",
              "4  2016-07-01  100+ Nobel laureates urge Greenpeace to stop o..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98PmgK31D9WX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1423a1c3-e96e-4821-b755-25dd3b3dc43a"
      },
      "source": [
        "dowjones.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1989, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49t3r3faD_RC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1feca9-711a-4c41-9369-2042e5796085"
      },
      "source": [
        "news.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73608, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bljg2emKD_9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbbf367-e4a0-43ab-b327-ed6fd6e49f1e"
      },
      "source": [
        "print(\"Number of days in stock price data : {}\" .format(len(set(dowjones.Date))))\n",
        "print(\"Number of days in news data : {}\" .format(len(set(news.Date))))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of days in stock price data : 1989\n",
            "Number of days in news data : 1989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ar6ZFCndqTF"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWOEvo4MfmxR"
      },
      "source": [
        "## Step 1 : Keeping Common date rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ45dnFmErKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6121968-5e52-47ae-e812-42ec7aa461a2"
      },
      "source": [
        "news = news[news.Date.isin(dowjones.Date)]  #Including only the dates that are present in the dowjones dataset.\n",
        "\n",
        "print('Number of days in stock price data : {}'.format(len(set(dowjones.Date))))\n",
        "print('Number of days in news data : {}'.format(len(set(news.Date))))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of days in stock price data : 1989\n",
            "Number of days in news data : 1989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHMLtUgXfx3d"
      },
      "source": [
        "## Step 2 : Removing unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tni9dJqbNOtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4919c11e-97b4-4565-a059-b0d3645b8eca"
      },
      "source": [
        "dowjones = dowjones.drop(['High','Low','Close','Volume','Adj Close'], axis = 1)\n",
        "dowjones = dowjones.set_index('Date')\n",
        "dowjones.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-07-01</th>\n",
              "      <td>17924.240234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-30</th>\n",
              "      <td>17712.759766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-29</th>\n",
              "      <td>17456.019531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-28</th>\n",
              "      <td>17190.509766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-06-27</th>\n",
              "      <td>17355.210938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Open\n",
              "Date                    \n",
              "2016-07-01  17924.240234\n",
              "2016-06-30  17712.759766\n",
              "2016-06-29  17456.019531\n",
              "2016-06-28  17190.509766\n",
              "2016-06-27  17355.210938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt_PaxQ2f5Mp"
      },
      "source": [
        "## Step 3 : Creating Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heohy9QOOgNL"
      },
      "source": [
        "# Target Variable, Diff = Tomorrow's Open Price - Today's Open Price\n",
        "# Based on the previous day news we will predict by how much the open price will decrease or increase from previous day's open price\n",
        "\n",
        "dowjones['Diff'] = -1 * dowjones.diff(periods = 1)\n",
        "dowjones['Date'] = dowjones.index\n",
        "dowjones = dowjones.reset_index(drop = True)\n",
        "dowjones = dowjones[dowjones.Diff.notnull()] #Removing the null values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw2mPwPrcBi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5008c2f8-aa79-45e0-e3ba-7893074554d9"
      },
      "source": [
        "dowjones.drop('Open', axis =1, inplace = True)\n",
        "dowjones.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diff</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>211.480468</td>\n",
              "      <td>2016-06-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>256.740235</td>\n",
              "      <td>2016-06-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>265.509765</td>\n",
              "      <td>2016-06-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-164.701172</td>\n",
              "      <td>2016-06-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-591.419921</td>\n",
              "      <td>2016-06-24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Diff        Date\n",
              "1  211.480468  2016-06-30\n",
              "2  256.740235  2016-06-29\n",
              "3  265.509765  2016-06-28\n",
              "4 -164.701172  2016-06-27\n",
              "5 -591.419921  2016-06-24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoRMcEqFgHWm"
      },
      "source": [
        "## Step 4 : Combining headlines of a date into a single list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwjwj5H_E7aK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc30c6ea-f744-4106-9c7f-a992142c752b"
      },
      "source": [
        "price = []  \n",
        "headlines = []  \n",
        "\n",
        "for row in dowjones.iterrows():\n",
        "\n",
        "  daily_headlines = [] # To store headlines of single date as a list of headlines.\n",
        "  date = row[1]['Date']\n",
        "  price.append(row[1]['Diff'])\n",
        "  for row in news[news.Date == date].iterrows():\n",
        "    daily_headlines.append(row[1]['News'])\n",
        "  \n",
        "  headlines.append(daily_headlines)\n",
        "\n",
        "  if len(price) % 500 == 0:\n",
        "    print(len(price))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "1000\n",
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pED9cu2tGeHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac958a7-ce04-4fc6-f355-6a9bd573f44b"
      },
      "source": [
        "# Printing sample input & output\n",
        "\n",
        "price[0], headlines[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211.48046800000157,\n",
              " ['Jamaica proposes marijuana dispensers for tourists at airports following legalisation: The kiosks and desks would give people a license to purchase up to 2 ounces of the drug to use during their stay',\n",
              "  \"Stephen Hawking says pollution and 'stupidity' still biggest threats to mankind: we have certainly not become less greedy or less stupid in our treatment of the environment over the past decade\",\n",
              "  'Boris Johnson says he will not run for Tory party leadership',\n",
              "  'Six gay men in Ivory Coast were abused and forced to flee their homes after they were pictured signing a condolence book for victims of the recent attack on a gay nightclub in Florida',\n",
              "  'Switzerland denies citizenship to Muslim immigrant girls who refused to swim with boys: report',\n",
              "  'Palestinian terrorist stabs israeli teen girl to death in her bedroom',\n",
              "  'Puerto Rico will default on $1 billion of debt on Friday',\n",
              "  'Republic of Ireland fans to be awarded medal for sportsmanship by Paris mayor.',\n",
              "  \"Afghan suicide bomber 'kills up to 40' - BBC News\",\n",
              "  'US airstrikes kill at least 250 ISIS fighters in convoy outside Fallujah, official says',\n",
              "  'Turkish Cop Who Took Down Istanbul Gunman Hailed a Hero',\n",
              "  \"Cannabis compounds could treat Alzheimer's by removing plaque-forming proteins from brain cells, research suggests\",\n",
              "  \"Japan's top court has approved blanket surveillance of the country's Muslims: 'They made us terrorist suspects, we never did anything wrong,' says Japanese Muslim, Mohammed Fujita\",\n",
              "  'CIA Gave Romania Millions to Host Secret Prisons',\n",
              "  'Groups urge U.N. to suspend Saudi Arabia from rights council',\n",
              "  'Googles free wifi at Indian railway stations is better than most of the countrys paid services',\n",
              "  \"Mounting evidence suggests 'hobbits' were wiped out by modern humans' ancestors 50,000 years ago.\",\n",
              "  \"The men who carried out Tuesday's terror attack at Istanbul's Ataturk Airport were from Russia, Uzbekistan and Kyrgyzstan, a Turkish offical said.\",\n",
              "  'Calls to suspend Saudi Arabia from UN Human Rights Council because of military aggresion in Yemen',\n",
              "  'More Than 100 Nobel Laureates Call Out Greenpeace For Anti-GMO Obstruction In Developing World',\n",
              "  'British pedophile sentenced to 85 years in US for trafficking child abuse images: Domminich Shaw, a kingpin of sexual violence against children, sent dozens of images online and discussed plans to assault and kill a child while on probation',\n",
              "  'US permitted 1,200 offshore fracks in Gulf of Mexico between 2010 and 2014 and allowed 72 billion gallons of chemical discharge in 2014.',\n",
              "  'We will be swimming in ridicule - French beach police to carry guns while in swimming trunks: Police lifeguards on Frances busiest beaches will carry guns and bullet-proof vests for the first time this summer amid fears that terrorists could target holidaymakers.',\n",
              "  \"UEFA says no minutes of silence for Istanbul victims at Euro 2016 because 'Turkey have already been eliminated'\",\n",
              "  'Law Enforcement Sources: Gun Used in Paris Terrorist Attacks Came from Phoenix'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EEvJ1hggW3t"
      },
      "source": [
        "## Normalizing the Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i678YCBEfXIV"
      },
      "source": [
        "max_price = max(price)\n",
        "min_price = min(price)\n",
        "mean_price = np.mean(price)\n",
        "def normalize_price(price):\n",
        "  return ((price - min_price)/(max_price - min_price))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hEJK4L_g8V7"
      },
      "source": [
        "norm_price = []\n",
        "for p in price:\n",
        "  norm_price.append(normalize_price(p))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiOWWtFhPGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f78af0-3f04-4bba-8431-73c8c98315b2"
      },
      "source": [
        "print(\"Maximum Normalized Price : {}\".format(max(norm_price)))\n",
        "print(\"Minimum Normalized Price : {}\".format(min(norm_price)))\n",
        "print(\"Mean Normalized Price : {}\".format(np.mean(norm_price)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum Normalized Price : 1.0\n",
            "Minimum Normalized Price : 0.0\n",
            "Mean Normalized Price : 0.4551577545098642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvYszRjDhkMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437640dd-6dc0-4a10-e9e8-49de5c8eac41"
      },
      "source": [
        "print(max(len(i) for i in headlines))\n",
        "print(min(len(i) for i in headlines))\n",
        "print(np.mean([len(i) for i in headlines]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "22\n",
            "24.996478873239436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MajndceCSner"
      },
      "source": [
        "## Cleaning the headlines text\n",
        "\n",
        "Expandng some of the words like 've to have 't to not and also removing unwanted characters and giving fullforms to abbreviations and ignoring stopwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmQqO4TvUmlb"
      },
      "source": [
        "# Function to expand usual short forms in english such as won't, can't, we're and so on.\n",
        "\n",
        "def decontracted(phrase):\n",
        "  if \"'\" in phrase:\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can't\", \"can not\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\",\" am\", phrase)\n",
        "\n",
        "  return phrase"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXPh5yfZUttJ"
      },
      "source": [
        "# Function to replace some of the text such as us, un & uk along with above mentioned and stopwords.\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "  text =text.lower()\n",
        "\n",
        "  if True:\n",
        "    text = text.split()\n",
        "    new_text = []\n",
        "\n",
        "    for word in text:\n",
        "      new_text.append(decontracted(word))\n",
        "\n",
        "    text = \" \".join(new_text)\n",
        "\n",
        "  text = re.sub(r'&amp;', ' ', text)\n",
        "  text = re.sub(r'0,0','00', text)\n",
        "  text = re.sub(r'[_\"\\-;%()|.,+&=*%.,!?:#@\\[\\]]',' ', text)\n",
        "  text = re.sub(r'\\'', ' ', text)\n",
        "  text = re.sub(r'\\$','$', text)\n",
        "  text = re.sub(r'u s','united states ', text)\n",
        "  text = re.sub(r'u k','united kingdom ', text)\n",
        "  text = re.sub(r'u n','united nations ', text)\n",
        "  text = re.sub(r'j k',' jk ', text)\n",
        "  text = re.sub(r' s ',' ', text)\n",
        "  text = re.sub(r' yr ',' year ', text)\n",
        "  text = re.sub(r' l g b t ','lgbt', text)\n",
        "  text = re.sub(r'0km ','0 km ', text)\n",
        "  \n",
        "\n",
        "  text = text.split()\n",
        "  stops = set(stopwords.words(\"english\"))\n",
        "  text = [w for w in text if not w in stops]\n",
        "  text = \" \".join(text)\n",
        "\n",
        "  return text"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaUD5US3Ym3k"
      },
      "source": [
        "# Calling above functions on the headlines.\n",
        "\n",
        "clean_headlines = []\n",
        "\n",
        "for daily_headlines in headlines:\n",
        "  \n",
        "  clean_daily_headlines = []\n",
        "  \n",
        "  for headline in  daily_headlines:\n",
        "    clean_daily_headlines.append(clean_text(headline))\n",
        "  \n",
        "  clean_headlines.append(clean_daily_headlines)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuBthJhEaIyr",
        "outputId": "de142e22-a129-48f9-bf5d-de9b623b1547"
      },
      "source": [
        "clean_headlines[0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jamaica proposes marijuana dispensers tourists airports following legalisation kiosks desks would give people license purchase 2 ounces drug use stay',\n",
              " 'stephen hawking says pollution istupidity still biggest threats mankind certainly become less greedy less stupid treatment environment past decade',\n",
              " 'boris johnson says run tory party leadership',\n",
              " 'six gay men ivory coast abused forced flee homes pictured signing condolence book victims recent attack gay nightclub florida',\n",
              " 'switzerland denies citizenship muslim immigrant girls refused swim boys report',\n",
              " 'palestinian terrorist stabs israeli teen girl death bedroom',\n",
              " 'puerto rico default $1 billion debt friday',\n",
              " 'republic ireland fans awarded medal sportsmanship paris mayor',\n",
              " 'afghan suicide bomber kills 40 bbc news',\n",
              " 'us airstrikes kill least 250 isis fighters convoy outside fallujah official says',\n",
              " 'turkish cop took istanbul gunman hailed hero',\n",
              " 'cannabis compounds could treat alzheimer removing plaque forming proteins brain cells research suggests',\n",
              " 'japan top court approved blanket surveillance country muslims nothey made us terrorist suspects never anything wrong says japanese muslim mohammed fujita',\n",
              " 'cia gave romania millions host secret prisons',\n",
              " 'groups urge united nations suspend saudi arabia rights council',\n",
              " 'googles free wifi indian railway stations better countrys paid services',\n",
              " 'mounting evidence suggests hobbits wiped modern humans ancestors 50000 years ago',\n",
              " 'men carried tuesday terror attack istanbul ataturk airport russia uzbekistan kyrgyzstan turkish offical said',\n",
              " 'calls suspend saudi arabia un human rights council military aggresion yemen',\n",
              " '100 nobel laureates call greenpeace anti gmo obstruction developing world',\n",
              " 'british pedophile sentenced 85 years us trafficking child abuse images domminich shaw kingpin sexual violence children sent dozens images online discussed plans assault kill child probation',\n",
              " 'us permitted 1 200 offshore fracks gulf mexico 2010 2014 allowed 72 billion gallons chemical discharge 2014',\n",
              " 'swimming ridicule french beach police carry guns swimming trunks police lifeguards frances busiest beaches carry guns bullet proof vests first time summer amid fears terrorists could target holidaymakers',\n",
              " 'uefa says minutes silence istanbul victims euro 2016 noturkey already eliminated',\n",
              " 'law enforcement sources gun used paris terrorist attacks came phoenix']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpvuYOmSbjXv",
        "outputId": "fc2efba9-50e3-41ee-8814-ea312e76ac58"
      },
      "source": [
        "words = [word for headlines in clean_headlines for headline in headlines for word in headline.split()]\n",
        "print(\"Total number of unique words : {}\".format(len(words)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique words : 615495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7nMT-j_b3CC"
      },
      "source": [
        "import collections\n",
        "\n",
        "word_counts = collections.Counter(words)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m17ydvqefUt"
      },
      "source": [
        "## Creating embedding vector using GloVe(Global Vectors) model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teyFXp19ecE2",
        "outputId": "4e6aa99c-81c9-4c53-f250-9d1f9795387c"
      },
      "source": [
        "embedding_index = {}\n",
        "\n",
        "with open('/content/glove.840B.300d.txt', encoding = 'utf-8') as f:\n",
        "  for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    embedding = np.asarray(values[1:], dtype = 'float32')\n",
        "    embedding_index[word] = embedding\n",
        "\n",
        "print(\"Word Embedding : \",len(embedding_index))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word Embedding :  2196016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfDlKA3gcAgs"
      },
      "source": [
        "# Since all words present in headlines won't be having the word embeddings we will define a threshold & remove words which occur below the threshold value.\n",
        "\n",
        "threshold = 10\n",
        "\n",
        "word_to_vector = {}\n",
        "\n",
        "value = 0\n",
        "\n",
        "for word, count in word_counts.items():\n",
        "  if count >= threshold or word in embedding_index:\n",
        "    word_to_vector[word] = value\n",
        "    value += 1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcO9ppnujtdj",
        "outputId": "b93bca79-6a81-4ef9-94d5-a4307e35b7ee"
      },
      "source": [
        "len(word_to_vector)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG_oyW4EjzKb",
        "outputId": "fbd876cb-fc26-4d71-bf90-fe8690ee06dd"
      },
      "source": [
        "# Tokens for unknown words(UNK) and padding(PAD).\n",
        "\n",
        "codes = [\"<UNK>\",\"<PAD>\"]\n",
        "\n",
        "for code in codes:\n",
        "  word_to_vector[code] = len(word_to_vector)\n",
        "\n",
        "# For reversing the vector to words\n",
        "vector_to_word = {}\n",
        "for word, value  in word_to_vector.items():\n",
        "  vector_to_word[value] = word\n",
        "\n",
        "usage_ratio = round(len(word_to_vector) / len(word_counts), 4)*100\n",
        "\n",
        "print(\"Total Number of unique words : {}\".format(len(word_counts)))\n",
        "print(\"Number of words we will use : {}\".format(len(word_to_vector)))\n",
        "print(\"Percentage of word we will use : {}%\".format(usage_ratio))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of unique words : 36710\n",
            "Number of words we will use : 31235\n",
            "Percentage of word we will use : 85.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhKFT7e2lKsu"
      },
      "source": [
        "## Creating embedding matrix\n",
        "\n",
        "1. **Type 1 Words:**\n",
        "<br>For words in headlines which occur above the threshold value and are present in GloVe we use glove word embeddings.<br>\n",
        "2. **Type 2 Words:**\n",
        "<br>For words which occur more than threshold value but not present in Glove, we will randomly initialise the word embeddings for those.\n",
        "3. **Type 3 Words:**<br>For words which occur less than threshold and not present in GloVe, we will create a single token \"<UNK>\" for them and assign a single word embedding for them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQcR5xKQk_lI",
        "outputId": "a3a0b9bc-540b-4ddd-a3dc-2c64926f0ac3"
      },
      "source": [
        "# Size of the vector dimensions\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "no_words = len(word_to_vector)\n",
        "\n",
        "#Creating a zero matrix for Type 2 Words\n",
        "word_embedding_matrix = np.zeros((no_words, embedding_dim))\n",
        "for word, i in word_to_vector.items():\n",
        "  if word in embedding_index:\n",
        "    word_embedding_matrix[i] = embedding_index[word]\n",
        "  else:\n",
        "    new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
        "    embedding_index[word] = new_embedding\n",
        "    word_embedding_matrix[i] = new_embedding\n",
        "\n",
        "print(len(word_embedding_matrix))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0EfncMgqfA6",
        "outputId": "19d1c3ed-560d-4b58-c4b4-49f558a8c70b"
      },
      "source": [
        "word_count =0\n",
        "unk_count = 0\n",
        "\n",
        "headlines_sequence = []\n",
        "for daily_headlines in clean_headlines:\n",
        "  daily_headlines_seq = []\n",
        "  for headlines in daily_headlines:\n",
        "    headlines_seq = []\n",
        "    for word in headlines.split():\n",
        "      word_count +=1\n",
        "      if word in word_to_vector:\n",
        "        headlines_seq.append(word_to_vector[word])\n",
        "      else:\n",
        "        headlines_seq.append(word_to_vector[\"<UNK>\"])\n",
        "        unk_count += 1\n",
        "    \n",
        "    daily_headlines_seq.append(headlines_seq)\n",
        "  headlines_sequence.append(daily_headlines_seq)\n",
        "  \n",
        "unk_percent = round(unk_count/word_count,4)*100\n",
        "\n",
        "print(\"Total number of words in headlines : {}\".format(word_count))\n",
        "print(\"Total number of unknown words in headlines : {}\".format(unk_count))\n",
        "print(\"Total percent of unknown words in headlines : {}%\".format(unk_percent))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words in headlines : 615495\n",
            "Total number of unknown words in headlines : 8027\n",
            "Total percent of unknown words in headlines : 1.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPxhX7YyskPd"
      },
      "source": [
        "## Padding & Truncating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u2sQP4xsWqM"
      },
      "source": [
        "lengths = []\n",
        "for headlines in headlines_sequence:\n",
        "  for headline in headlines:\n",
        "    lengths.append(len(headline))\n",
        "\n",
        "lengths = pd.DataFrame(lengths, columns = ['Counts'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "d1uNNxYVtHaj",
        "outputId": "3e69bcf9-5e81-435d-82cc-f4f2b0e220f1"
      },
      "source": [
        "lengths.describe()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>49693.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>12.385950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.773807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Counts\n",
              "count  49693.000000\n",
              "mean      12.385950\n",
              "std        6.773807\n",
              "min        1.000000\n",
              "25%        7.000000\n",
              "50%       10.000000\n",
              "75%       16.000000\n",
              "max       41.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_TtC0TbtQAp"
      },
      "source": [
        "### Observation\n",
        "\n",
        "It can be seen that around 75% of the headlines are of length 16 words and to minimize training time we wil limit the max length of single headline to 16 words and that of a day to 200 words.\n",
        "\n",
        "If a headline is less than 16 words we will keep it as it is, if it is longer than 16 words then we will truncate it from right and apend first 16 words.\n",
        "\n",
        "If daily headlines is less than 200 words we will pad it, if it is greater than 200 words we will truncate it from the right side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O48803k8tfRa"
      },
      "source": [
        "max_headline_length = 16\n",
        "max_daily_length = 200\n",
        "pad_headlines =[]\n",
        "\n",
        "for headlines in headlines_sequence:\n",
        "  pad_daily_headlines = []\n",
        "  for headline in headlines:\n",
        "    if len(headline) <= max_headline_length:\n",
        "      for word in headline:\n",
        "        pad_daily_headlines.append(word)\n",
        "      \n",
        "    else:\n",
        "      headline = headline[:max_headline_length]\n",
        "      for word in headline:\n",
        "        pad_daily_headlines.append(word)\n",
        "\n",
        "  if len(pad_daily_headlines) < max_daily_length:\n",
        "    for i in range(max_daily_length - len(pad_daily_headlines)):\n",
        "      pad = word_to_vector[\"<PAD>\"]\n",
        "      pad_daily_headlines.append(pad)\n",
        "\n",
        "  else:\n",
        "    pad_daily_headlines = pad_daily_headlines[:max_daily_length]\n",
        "\n",
        "  pad_headlines.append(pad_daily_headlines)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOfhdaRPxv6N"
      },
      "source": [
        "# Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_HcYpAowteR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pad_headlines, norm_price, test_size = 0.15, random_state = 43)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AvcsN5ZyTq0",
        "outputId": "3a5c9d17-a32a-4b6b-e501-bf3f49337753"
      },
      "source": [
        "print(\"Length of training datasets : X = {0} Y = {1}\".format(len(X_train), len(y_train)))\n",
        "print(\"Length of testing datasets : X = {0} Y = {1}\".format(len(X_test), len(y_test)))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training datasets : X = 1689 Y = 1689\n",
            "Length of testing datasets : X = 299 Y = 299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVYAb0b4yzRo"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av810MRBy3l2"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfCalM16ypt0"
      },
      "source": [
        "filter_length = 5\n",
        "dropout = 0.5\n",
        "learning_rate = 0.001\n",
        "weights = initializers.TruncatedNormal(mean = 0.0, stddev = 0.1, seed = 2)\n",
        "no_filter = 16\n",
        "rnn_output_size = 128\n",
        "hidden_dim = 128"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo8kipfC0rDT"
      },
      "source": [
        "## Creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRa3PDp60puU"
      },
      "source": [
        "def build_model():\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Creating an embedding layer.\n",
        "  model.add(Embedding(no_words, embedding_dim, weights = [word_embedding_matrix], input_length = max_daily_length))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  # Creating 2 1-Dimensional Convolutional layer.\n",
        "  model.add(Convolution1D(filters = no_filter, kernel_size = filter_length, padding = 'same', activation = 'relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Convolution1D(filters = no_filter, kernel_size = filter_length, padding = 'same', activation = 'relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  # Creating RNN Layer(LSTM).\n",
        "\n",
        "  model.add(LSTM(rnn_output_size, activation=None, kernel_initializer=weights, dropout = dropout))\n",
        "\n",
        "  # Creating Dense network\n",
        "\n",
        "  model.add(Dense(hidden_dim, kernel_initializer=weights))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Dense(1, kernel_initializer=weights, name = 'output'))\n",
        "\n",
        "  # Compiling the model.\n",
        "  model.compile(loss = 'mean_squared_error', optimizer = Adam(lr = learning_rate, clipvalue = 1.0))#For solving exploding gradients problem clipvalue is assigned 1\n",
        "\n",
        "  return model"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKZwBLu13mg4"
      },
      "source": [
        "## Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7iqGMiC2uSc",
        "outputId": "31753515-b205-4b8f-ae27-2c0baee85861"
      },
      "source": [
        "model = build_model()\n",
        "print()\n",
        "save_best_weights = 'best_weights.h5'\n",
        "\n",
        "callbacks = [ModelCheckpoint(save_best_weights, monitor = 'val_loss', save_best_only = True),\n",
        "             EarlyStopping(monitor = 'val_loss',patience = 5, verbose = 1, mode = 'auto'),\n",
        "             ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, verbose = 1, patience = 3)]\n",
        "\n",
        "history = model.fit([X_train], y_train, batch_size = 128, epochs = 50, validation_split = 0.15, verbose = True, shuffle = True,  callbacks = callbacks)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "12/12 [==============================] - 13s 1s/step - loss: 0.0594 - val_loss: 0.0455\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 12s 997ms/step - loss: 0.0252 - val_loss: 0.0443\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0195 - val_loss: 0.0369\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 12s 989ms/step - loss: 0.0153 - val_loss: 0.0279\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0130 - val_loss: 0.0181\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0111 - val_loss: 0.0122\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0100 - val_loss: 0.0110\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0106 - val_loss: 0.0119\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0102 - val_loss: 0.0117\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 12s 999ms/step - loss: 0.0102 - val_loss: 0.0097\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 12s 994ms/step - loss: 0.0099 - val_loss: 0.0096\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 12s 998ms/step - loss: 0.0098 - val_loss: 0.0095\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0094 - val_loss: 0.0099\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0093\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "12/12 [==============================] - 12s 986ms/step - loss: 0.0093 - val_loss: 0.0103\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 12s 995ms/step - loss: 0.0091 - val_loss: 0.0100\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0091 - val_loss: 0.0101\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0092\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "12/12 [==============================] - 12s 1s/step - loss: 0.0092 - val_loss: 0.0101\n",
            "Epoch 00017: early stopping\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 200, 300)          9370500   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 200, 16)           24016     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 200, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 200, 16)           1296      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 200, 16)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               74240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 9,486,693\n",
            "Trainable params: 9,486,693\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOVLrhxY4vBR",
        "outputId": "520b8787-08e1-4967-e786-d4e781df7450"
      },
      "source": [
        "predictions = model.predict([X_test], verbose = True)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 66ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu1BnKRT6UK7",
        "outputId": "bf58c92b-26c9-48ac-830f-4645108223d9"
      },
      "source": [
        "mse(y_test, predictions)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.007373820714071627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea1n-YpF6YYI"
      },
      "source": [
        "def unnormalize(price):\n",
        "  price = price*(max_price - min_price)+min_price\n",
        "  return price"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot9adHTS6o-K"
      },
      "source": [
        "unnorm_predictions = []\n",
        "for pred in predictions:\n",
        "  unnorm_predictions.append(unnormalize(pred))\n",
        "\n",
        "unnorm_y_test = []\n",
        "for y in y_test:\n",
        "  unnorm_y_test.append(unnormalize(y))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBiRxYeR7XkT",
        "outputId": "1ba8999d-24f7-4876-d649-a5985f796076"
      },
      "source": [
        "mse(unnorm_y_test, unnorm_predictions)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21174.920262106425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8xMS4kF7dBP",
        "outputId": "4955e648-f091-4d57-d4cc-133e385d0242"
      },
      "source": [
        "pd.Series(unnorm_y_test).describe()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    299.000000\n",
              "mean       6.710047\n",
              "std      135.879128\n",
              "min     -518.189453\n",
              "25%      -51.799805\n",
              "50%       11.708985\n",
              "75%       81.265137\n",
              "max      495.719727\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsvd12Wa8c7q"
      },
      "source": [
        "# Making predictions on news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1thqega71zC"
      },
      "source": [
        "def news_to_vector(news):\n",
        "  vector = []\n",
        "  for word in news.split():\n",
        "    if word in word_to_vector:\n",
        "      vector.append(word_to_vector[word])\n",
        "    else:\n",
        "      vector.append(word_to_vector[\"<UNK>\"])\n",
        "  \n",
        "  return vector"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVmeJE0v88TI"
      },
      "source": [
        "def news_padding(news):\n",
        "\n",
        "  padded_news = news\n",
        "  if len(padded_news) < max_daily_length:\n",
        "    for i in range(max_daily_length - len(padded_news)):\n",
        "      padded_news.append(word_to_Vector[\"<PAD>\"])\n",
        "\n",
        "  elif len(padded_news)  > max_daily_length:\n",
        "      padded_news = padded_news[:max_daily_length]\n",
        "\n",
        "  return padded_news"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUeMhs2097cN",
        "outputId": "1a314f4e-bc6a-407c-ba87-946ce1c167bf"
      },
      "source": [
        "todays_headlines = \"Woman says note from Chinese 'prisoner' was hidden in new purse. \\\n",
        "               21,000 AT&T workers poised for Monday strike \\\n",
        "               housands march against Trump climate policies in D.C., across USA \\\n",
        "               Kentucky judge won't hear gay adoptions because it's not in the child's \\\"best interest\\\" \\\n",
        "               Multiple victims shot in UTC area apartment complex \\\n",
        "               Drones Lead Police to Illegal Dumping in Riverside County | NBC Southern California \\\n",
        "               An 86-year-old Californian woman has died trying to fight a man who was allegedly sexually assaulting her 61-year-old friend. \\\n",
        "               Fyre Festival Named in $5Million+ Lawsuit after Stranding Festival-Goers on Island with Little Food, No Security. \\\n",
        "               The \\\"Greatest Show on Earth\\\" folds its tent for good \\\n",
        "               U.S.-led fight on ISIS have killed 352 civilians: Pentagon \\\n",
        "               Woman offers undercover officer sex for $25 and some Chicken McNuggets \\\n",
        "               Ohio bridge refuses to fall down after three implosion attempts \\\n",
        "               Jersey Shore MIT grad dies in prank falling from library dome \\\n",
        "               New York graffiti artists claim McDonald's stole work for latest burger campaign \\\n",
        "               SpaceX to launch secretive satellite for U.S. intelligence agency \\\n",
        "               Severe Storms Leave a Trail of Death and Destruction Through the U.S. \\\n",
        "               Hamas thanks N. Korea for its support against ‘Israeli occupation’ \\\n",
        "               Baker Police officer arrested for allegedly covering up details in shots fired investigation \\\n",
        "               Miami doctor’s call to broker during baby’s delivery leads to $33.8 million judgment \\\n",
        "               Minnesota man gets 15 years for shooting 5 Black Lives Matter protesters \\\n",
        "               South Australian woman facing possible 25 years in Colombian prison for drug trafficking \\\n",
        "               The Latest: Deal reached on funding government through Sept. \\\n",
        "               Russia flaunts Arctic expansion with new military bases\"\n",
        "\n",
        "      \n",
        "clean_news = clean_text(todays_headlines)\n",
        "\n",
        "vector_news = news_to_vector(clean_news)\n",
        "\n",
        "padded_news = news_padding(vector_news)\n",
        "\n",
        "padded_news = np.array([padded_news]).reshape((1,-1))\n",
        "\n",
        "pred = model.predict([padded_news])\n",
        "\n",
        "price_change = unnormalize(pred)\n",
        "\n",
        "print(\"The Dow Jones should open {} from the previous open\".format(np.round(price_change[0][0],2)))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Dow Jones should open -52.150001525878906 from the previous open\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}